from kafka import KafkaProducer
import json
import time
import random
from datetime import datetime
import pandas as pd

# Load movie IDs from the Parquet file generated by batch_ingestion.py
try:
    df_movies = pd.read_parquet("data/processed/movies")
    movie_ids = df_movies['movieId'].dropna().astype(str).unique().tolist()
except Exception as e:
    print("‚ùå Failed to load movie IDs from data/processed/movies:")
    print(e)
    exit(1)

# Create Kafka producer
producer = KafkaProducer(
    bootstrap_servers='localhost:9092',
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

print(f"‚úÖ Kafka producer started. Loaded {len(movie_ids)} movie IDs.")

# Generate random events and send to Kafka from batch files as mock data
try:
    while True:
        event = {
            "user_id": str(random.randint(1000, 1100)),
            "movie_id": random.choice(movie_ids),
            "watch_time": datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        }

        producer.send("movie-stream", value=event)
        print(f"üì§ Sent: {event}")
        time.sleep(random.randint(1, 3))

except KeyboardInterrupt:
    print("\nüõë Producer manually stopped.")
